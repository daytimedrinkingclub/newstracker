# twitter thread on which we are building the MVP ( LOL )

- This is a readme generated by ai for an AI agent who tracks topics of interest for you
  It analyses all postive data for your topic
  It analyses all negative data for your topic
  It checks for data factually
  It creates a summary of the topic
  It creates a positive sumamry
  
- Rest is left to the user the app doesnt provide conclusions only data from all forms and validations

```bash 
Nishant Singh
@iNishant
路
4h
Feel free to copy this good/bad idea. DM if you want to build this together.

LLM-driven news timeline generator. I want to stay updated on all events related to certain issues. While this is almost search engine territory, might be a fun experiment to build from scratch.
Neel Seth
@NeelSeth7
10$/month  ? Mein deta raat tak. News tracker agent, track your own keywords latest news ?
2:17 PM 路 Jul 20, 2024
路
63
 Views
View post engagements
Related posts

Nishant Singh
@iNishant
路
3h
De dunga , bana tu

P0 requirements
- Basic timeline UI with timestamps, summaries
- Each summary with sources

Sample input "Puja Khedkar controversy"
```

## P0 product and user journey

- user signs up with email
- user lands on plan selection page
  - the user can opt for free plan
    - free plan has no limitations of number of analysis but they can also add only 10 keywords to track
    - the user needs to provide their own anthropic and tavily api keys
  - the user can opt for paid plan
    - the paid plan user can add only 10 keywords and run analysis 20 times a day in total or twice per keyword for that matter
    - the paid user does not provide any keys, we use the keys stored in our env variables as we are charging the user
- user post selecting the plan lands on keyword additon page
  - here the user can add maximum 10 keywords for all kind of plans
  - user can come back to the page and delete a keyword add new but total keywords added should not cross 10
- Once keywords are added the user can go the feed page where the list of keywords is visible in tiles waiting to run the first analysis
  - the user clicks on run analysis
  - we run ai based background simulation to run analysis
  - we keep updating the analysis status in a table to be tracked
  - once analysis is completed we update the analysis status as well the data for the keyword
- the user can click on any keyword tile on the feed page to see details
  - the detailss page has a sumamry, positive content, negative cotent sources of all content and fact checked sources
- Users can signup and login add keywords etc without selecting any plan also, however if the user is not a paid plan user or a free plan user ( as to start free plan api keys are needed ) the start analysis button will prompt the user to select any one of the plan

## Technology stack

- Tavily API for search
- Anthropic LLM for ai
- Flask python backend
- Jinja 2 templates - tailwind css
- Supabase with email password
- Heroku for hosting
- Supabase database 
- RedisCloud connection to manage long running and background task

### Folder Structure

```bash
news_app/
    backend/ # flask
        app/
            templates/
                base.html # base template with basic layout
                components/
                    header.html # header component
                    footer.html # footer component
                onboarding/
                    keyword.html # News keyword selection / removal page
                    plans.html # User plan selection page
                auth/
                    login.html # Login page, login with supabase - server side
                    signup.html # Signup page with supabase - server side
                main/
                    feed.html # News Feed
                    news.html # News detail page
            routes/
                __init__.py # empty routes file
                auth.py # authentication routes
                main.py # all other rotues
            models/ # this has only services for models as tables are directly created on supabase
                __init__.py # empty init file
                data_service.py # data services to work with supabase database
            services/
                prompts/
                    promptfile.txt # prompt for ai
                tools/
                    search.json # tools available for ai agent
                    positive.json # tools available for ai agent
                    negative.json # tools available for ai agent
                    summary.json # tools available for ai agent
                __init__.py # services init file empty
                agent.py # main agent service with recusrive ai simulation
                ai.py # additional ai tool
                context.py # ai analysis context builder for simulation
                search.py # search service
                supabase_auth.py # supabase auth services create user / update etc
            utils/
                __init__.py # empty init file
                redis_task_manager.py # empty file need to work on this
            static/
                css/ #empty folder
                js/ # empty
            __init__.py
            env # local env file for local testing loaded using python dotenv
            config.py # config of the app
            extensions.py # app extensions
            supabase_config.py # supabase client setup
            redis_config.py # redis connection setup
        myvenv/ # local virtual environment
        requirements.txt 
        Procfile # heroku gunicorn run file
        run.py # local flask run file
        run_worker.py # running redis worker
    readme.md
```


### Supabase tables

1. user_plan
```sql
    create table
    public.user_plan (
        id uuid not null default uuid_generate_v4 (),
        plan public.plan_enum not null,
        user_id uuid not null,
        created_at timestamp with time zone null default current_timestamp,
        updated_at timestamp without time zone null default (now() at time zone 'utc'::text),
        constraint user_plan_pkey primary key (id),
        constraint user_plan_user_id_key unique (user_id),
        constraint fk_user_plan_user foreign key (user_id) references auth.users (id)
    ) tablespace pg_default;
```
2. user_keyowrd
```sql
create table
  public.user_keyword (
    id uuid not null default uuid_generate_v4 (),
    keyword character varying(500) not null,
    user_id uuid not null,
    created_at timestamp with time zone null default current_timestamp,
    constraint user_keyword_pkey primary key (id),
    constraint fk_user_keyword_user foreign key (user_id) references auth.users (id)
  ) tablespace pg_default;
```
3. keyword_analysis
```sql
create table
  public.keyword_analysis (
    id uuid not null default uuid_generate_v4 (),
    user_id uuid not null,
    keyword_id uuid not null,
    created_at timestamp with time zone null default current_timestamp,
    status text null,
    job_id text null,
    updated_at timestamp without time zone null,
    keyword_summary_id uuid null,
    constraint keyword_analysis_pkey primary key (id),
    constraint fk_keyword_analysis_user foreign key (user_id) references auth.users (id),
    constraint keyword_analysis_keyword_id_fkey foreign key (keyword_id) references user_keyword (id),
    constraint keyword_analysis_keyword_summary_id_fkey foreign key (keyword_summary_id) references keyword_summary (id)
  ) tablespace pg_default;
```
4. keyword_summary
```sql
create table
  public.keyword_summary (
    id uuid not null default uuid_generate_v4 (),
    keyword character varying(500) not null,
    news_summary text not null,
    postive_summary text not null,
    postive_sources_links text not null,
    negative_summary text not null,
    negative_sources_links text not null,
    user_id uuid not null,
    created_at timestamp with time zone null default current_timestamp,
    updated_at timestamp with time zone null default current_timestamp,
    keyword_id uuid null,
    constraint keyword_summary_pkey primary key (id),
    constraint fk_keyword_summary_user foreign key (user_id) references auth.users (id),
    constraint keyword_summary_keyword_id_fkey foreign key (keyword_id) references user_keyword (id)
  ) tablespace pg_default;
```
5. user_api_token
```sql
create table
  public.user_api_token (
    id uuid not null default uuid_generate_v4 (),
    anthropic_api_key character varying(500) null,
    tavily_api_key character varying(500) null,
    user_id uuid not null,
    created_at timestamp with time zone null default current_timestamp,
    constraint user_api_token_pkey primary key (id),
    constraint user_api_token_user_id_key unique (user_id),
    constraint fk_user_api_token_user foreign key (user_id) references auth.users (id)
  ) tablespace pg_default;
```
6. analysis_messages
```sql
create table
  public.analysis_messages (
    id uuid not null default uuid_generate_v4 (),
    keyword_analysis_id uuid not null,
    role public.role_enum not null,
    content text not null,
    tool_name text null,
    tool_use_id text null,
    tool_input jsonb null,
    tool_result text null,
    created_at timestamp with time zone null default current_timestamp,
    constraint analysis_messages_pkey primary key (id),
    constraint analysis_messages_keyword_analysis_id_fkey foreign key (keyword_analysis_id) references keyword_analysis (id)
  ) tablespace pg_default;
```